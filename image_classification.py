# -*- coding: utf-8 -*-
"""Image Classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bzw9LAa4DLPZgK7xhOPy-OaMxAWjecWW
"""

# Install TensorFlow
!pip install tensorflow

# Import all necessary Libraries
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

#Load and Preprocess Data

# Load CIFAR-10 dataset
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

#Visualize the Data

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

# Plot the first 25 images from the training set and display the class name below each image
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i])
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()

# Build the Convolutional Neural Network (CNN)

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))

# Compile the Mode

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Train the Mode

history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images,test_labels))

# Evaluate the Model

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f'Test accuracy: {test_acc}')

# Plot Training and Validation Accuracy

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()

model.summary()

print("Training data shape:", train_images.shape)
print("Test data shape:", test_images.shape)
print("Pixel range:", train_images.min(), "-", train_images.max())

history.history.keys()  # to check available metrics

# Plot training and validation accuracy/loss
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f'Test accuracy: {test_acc:.4f}')
print(f'Test loss: {test_loss:.4f}')

# Predict the class of the first 10 images in the test set
predictions = model.predict(test_images[:10])

# Convert logits to probabilities
probabilities = tf.nn.softmax(predictions)
predicted_labels = tf.argmax(probabilities, axis=1)
actual_labels = test_labels[:10].flatten()

print("Predicted labels:", predicted_labels.numpy())
print("Actual labels:", actual_labels)

plt.figure(figsize=(10, 10))
for i in range(10):
    plt.subplot(5, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(test_images[i])
    plt.xlabel(f"Predicted: {class_names[predicted_labels[i]]}\nActual: {class_names[actual_labels[i]]}")
plt.show()

# Save the model
model.save('cifar10_model.h5')

# Load the model
new_model = tf.keras.models.load_model('cifar10_model.h5')
new_model.summary()

# Make predictions on the test set
predictions = model.predict(test_images)

# Convert logits to probabilities
probabilities = tf.nn.softmax(predictions)

# Get the predicted labels
predicted_labels = tf.argmax(probabilities, axis=1)

# Flatten the actual labels array for comparison
actual_labels = test_labels.flatten()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Compute the confusion matrix
cm = confusion_matrix(actual_labels, predicted_labels)

# Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

